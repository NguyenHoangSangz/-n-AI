{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nguyen_Hoang_Sang_19146249",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AsAJxDZKRs_P"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import Flatten, Dense, Dropout, Activation\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url='/content/drive/MyDrive/Nguyen_Hoang _Sang AI/Train'\n",
        "generator= ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
        "train_data=generator.flow_from_directory(url,target_size=(64,64),batch_size=10,class_mode='categorical',subset='training')\n",
        "validation_data=generator.flow_from_directory(url,target_size=(64,64),batch_size=10,class_mode='categorical',subset='validation')\n",
        "label = list()\n",
        "for key in train_data.class_indices:\n",
        "  label.append(key)\n",
        "validation_data.class_indices\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieD3ix3fSYv8",
        "outputId": "ab379de8-ad9d-4ce0-ef2b-46b9ab7178e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2744 images belonging to 15 classes.\n",
            "Found 676 images belonging to 15 classes.\n",
            "['Bean', 'Bitter_Gourd', 'Bottle_Gourd', 'Brinjal', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Cucumber', 'Papaya', 'Potato', 'Pumpkin', 'Radish', 'Tomato']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHxZ68U1l7_K",
        "outputId": "2dd6f21c-4969-46ef-a4ab-df686c687ef1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= Sequential()\n",
        "model.add(Conv2D(32,(3,3),activation = 'relu', kernel_initializer= 'he_uniform',padding ='same',input_shape=(64,64,3)))\n",
        "model.add(Conv2D(32,(3,3),activation = 'relu', kernel_initializer= 'he_uniform',padding ='same'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation = 'relu', kernel_initializer='he_uniform' ))\n",
        "model.add(Dense(15, activation='softmax'))\n",
        "opt=Adam(lr=0.002)\n",
        "model.compile (optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history=model.fit(train_data,epochs=330,batch_size=64,validation_data=validation_data,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU_7dDEYu4UL",
        "outputId": "9ae2835f-f87e-4d46-944a-fa91c1942268"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275/275 [==============================] - 13s 36ms/step - loss: 2.1398 - accuracy: 0.4034 - val_loss: 1.2918 - val_accuracy: 0.6124\n",
            "Epoch 2/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.7456 - accuracy: 0.7569 - val_loss: 1.3477 - val_accuracy: 0.6080\n",
            "Epoch 3/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 0.2118 - accuracy: 0.9351 - val_loss: 1.1236 - val_accuracy: 0.6967\n",
            "Epoch 4/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0899 - accuracy: 0.9781 - val_loss: 1.3183 - val_accuracy: 0.6598\n",
            "Epoch 5/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0344 - accuracy: 0.9916 - val_loss: 1.3768 - val_accuracy: 0.7086\n",
            "Epoch 6/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0190 - accuracy: 0.9964 - val_loss: 1.5941 - val_accuracy: 0.6879\n",
            "Epoch 7/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.1494 - accuracy: 0.9541 - val_loss: 1.8640 - val_accuracy: 0.6405\n",
            "Epoch 8/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.1478 - accuracy: 0.9595 - val_loss: 1.7929 - val_accuracy: 0.6849\n",
            "Epoch 9/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 1.7846 - val_accuracy: 0.7115\n",
            "Epoch 10/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 9.1126e-04 - accuracy: 1.0000 - val_loss: 1.8785 - val_accuracy: 0.7204\n",
            "Epoch 11/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.4016e-04 - accuracy: 1.0000 - val_loss: 1.9009 - val_accuracy: 0.7204\n",
            "Epoch 12/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 1.4759e-04 - accuracy: 1.0000 - val_loss: 1.9247 - val_accuracy: 0.7249\n",
            "Epoch 13/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.0817e-04 - accuracy: 1.0000 - val_loss: 1.9534 - val_accuracy: 0.7249\n",
            "Epoch 14/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 8.2915e-05 - accuracy: 1.0000 - val_loss: 1.9743 - val_accuracy: 0.7293\n",
            "Epoch 15/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.5262e-05 - accuracy: 1.0000 - val_loss: 1.9980 - val_accuracy: 0.7308\n",
            "Epoch 16/330\n",
            "275/275 [==============================] - 9s 35ms/step - loss: 5.2229e-05 - accuracy: 1.0000 - val_loss: 2.0206 - val_accuracy: 0.7352\n",
            "Epoch 17/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.2761e-05 - accuracy: 1.0000 - val_loss: 2.0438 - val_accuracy: 0.7367\n",
            "Epoch 18/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 3.5173e-05 - accuracy: 1.0000 - val_loss: 2.0627 - val_accuracy: 0.7367\n",
            "Epoch 19/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.9250e-05 - accuracy: 1.0000 - val_loss: 2.0860 - val_accuracy: 0.7352\n",
            "Epoch 20/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.4508e-05 - accuracy: 1.0000 - val_loss: 2.1045 - val_accuracy: 0.7352\n",
            "Epoch 21/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.0677e-05 - accuracy: 1.0000 - val_loss: 2.1235 - val_accuracy: 0.7367\n",
            "Epoch 22/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.7465e-05 - accuracy: 1.0000 - val_loss: 2.1402 - val_accuracy: 0.7352\n",
            "Epoch 23/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.4758e-05 - accuracy: 1.0000 - val_loss: 2.1591 - val_accuracy: 0.7337\n",
            "Epoch 24/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.2619e-05 - accuracy: 1.0000 - val_loss: 2.1781 - val_accuracy: 0.7352\n",
            "Epoch 25/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.0722e-05 - accuracy: 1.0000 - val_loss: 2.1967 - val_accuracy: 0.7352\n",
            "Epoch 26/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 9.1812e-06 - accuracy: 1.0000 - val_loss: 2.2168 - val_accuracy: 0.7382\n",
            "Epoch 27/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 7.8531e-06 - accuracy: 1.0000 - val_loss: 2.2351 - val_accuracy: 0.7382\n",
            "Epoch 28/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 6.7456e-06 - accuracy: 1.0000 - val_loss: 2.2519 - val_accuracy: 0.7382\n",
            "Epoch 29/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 5.7836e-06 - accuracy: 1.0000 - val_loss: 2.2691 - val_accuracy: 0.7367\n",
            "Epoch 30/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 4.9715e-06 - accuracy: 1.0000 - val_loss: 2.2864 - val_accuracy: 0.7367\n",
            "Epoch 31/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 4.2670e-06 - accuracy: 1.0000 - val_loss: 2.3026 - val_accuracy: 0.7367\n",
            "Epoch 32/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 3.6759e-06 - accuracy: 1.0000 - val_loss: 2.3192 - val_accuracy: 0.7367\n",
            "Epoch 33/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 3.1484e-06 - accuracy: 1.0000 - val_loss: 2.3376 - val_accuracy: 0.7367\n",
            "Epoch 34/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.7208e-06 - accuracy: 1.0000 - val_loss: 2.3558 - val_accuracy: 0.7367\n",
            "Epoch 35/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.3381e-06 - accuracy: 1.0000 - val_loss: 2.3725 - val_accuracy: 0.7367\n",
            "Epoch 36/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.0206e-06 - accuracy: 1.0000 - val_loss: 2.3875 - val_accuracy: 0.7367\n",
            "Epoch 37/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.7380e-06 - accuracy: 1.0000 - val_loss: 2.4072 - val_accuracy: 0.7367\n",
            "Epoch 38/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.4997e-06 - accuracy: 1.0000 - val_loss: 2.4240 - val_accuracy: 0.7367\n",
            "Epoch 39/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.2948e-06 - accuracy: 1.0000 - val_loss: 2.4380 - val_accuracy: 0.7382\n",
            "Epoch 40/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.1165e-06 - accuracy: 1.0000 - val_loss: 2.4559 - val_accuracy: 0.7382\n",
            "Epoch 41/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 9.6444e-07 - accuracy: 1.0000 - val_loss: 2.4723 - val_accuracy: 0.7382\n",
            "Epoch 42/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 8.3103e-07 - accuracy: 1.0000 - val_loss: 2.4877 - val_accuracy: 0.7382\n",
            "Epoch 43/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 7.1660e-07 - accuracy: 1.0000 - val_loss: 2.5039 - val_accuracy: 0.7382\n",
            "Epoch 44/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.1968e-07 - accuracy: 1.0000 - val_loss: 2.5200 - val_accuracy: 0.7367\n",
            "Epoch 45/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.3336e-07 - accuracy: 1.0000 - val_loss: 2.5394 - val_accuracy: 0.7367\n",
            "Epoch 46/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.6037e-07 - accuracy: 1.0000 - val_loss: 2.5532 - val_accuracy: 0.7382\n",
            "Epoch 47/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.9816e-07 - accuracy: 1.0000 - val_loss: 2.5729 - val_accuracy: 0.7367\n",
            "Epoch 48/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.4377e-07 - accuracy: 1.0000 - val_loss: 2.5865 - val_accuracy: 0.7382\n",
            "Epoch 49/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.9650e-07 - accuracy: 1.0000 - val_loss: 2.6051 - val_accuracy: 0.7382\n",
            "Epoch 50/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.5675e-07 - accuracy: 1.0000 - val_loss: 2.6214 - val_accuracy: 0.7382\n",
            "Epoch 51/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.2148e-07 - accuracy: 1.0000 - val_loss: 2.6370 - val_accuracy: 0.7382\n",
            "Epoch 52/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.9159e-07 - accuracy: 1.0000 - val_loss: 2.6529 - val_accuracy: 0.7382\n",
            "Epoch 53/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.6569e-07 - accuracy: 1.0000 - val_loss: 2.6691 - val_accuracy: 0.7382\n",
            "Epoch 54/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.4267e-07 - accuracy: 1.0000 - val_loss: 2.6841 - val_accuracy: 0.7367\n",
            "Epoch 55/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.2429e-07 - accuracy: 1.0000 - val_loss: 2.7006 - val_accuracy: 0.7367\n",
            "Epoch 56/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.0713e-07 - accuracy: 1.0000 - val_loss: 2.7172 - val_accuracy: 0.7367\n",
            "Epoch 57/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 9.1840e-08 - accuracy: 1.0000 - val_loss: 2.7324 - val_accuracy: 0.7382\n",
            "Epoch 58/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 7.9415e-08 - accuracy: 1.0000 - val_loss: 2.7453 - val_accuracy: 0.7396\n",
            "Epoch 59/330\n",
            "275/275 [==============================] - 10s 38ms/step - loss: 6.8988e-08 - accuracy: 1.0000 - val_loss: 2.7626 - val_accuracy: 0.7396\n",
            "Epoch 60/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.0430e-08 - accuracy: 1.0000 - val_loss: 2.7767 - val_accuracy: 0.7411\n",
            "Epoch 61/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 5.2089e-08 - accuracy: 1.0000 - val_loss: 2.7873 - val_accuracy: 0.7396\n",
            "Epoch 62/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 4.5833e-08 - accuracy: 1.0000 - val_loss: 2.8008 - val_accuracy: 0.7396\n",
            "Epoch 63/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 3.9881e-08 - accuracy: 1.0000 - val_loss: 2.8154 - val_accuracy: 0.7411\n",
            "Epoch 64/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 3.4755e-08 - accuracy: 1.0000 - val_loss: 2.8326 - val_accuracy: 0.7382\n",
            "Epoch 65/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.9976e-08 - accuracy: 1.0000 - val_loss: 2.8450 - val_accuracy: 0.7411\n",
            "Epoch 66/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.6327e-08 - accuracy: 1.0000 - val_loss: 2.8543 - val_accuracy: 0.7382\n",
            "Epoch 67/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.2243e-08 - accuracy: 1.0000 - val_loss: 2.8666 - val_accuracy: 0.7382\n",
            "Epoch 68/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.9028e-08 - accuracy: 1.0000 - val_loss: 2.8737 - val_accuracy: 0.7367\n",
            "Epoch 69/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.6509e-08 - accuracy: 1.0000 - val_loss: 2.8778 - val_accuracy: 0.7396\n",
            "Epoch 70/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.4640e-08 - accuracy: 1.0000 - val_loss: 2.8887 - val_accuracy: 0.7396\n",
            "Epoch 71/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.2468e-08 - accuracy: 1.0000 - val_loss: 2.8873 - val_accuracy: 0.7396\n",
            "Epoch 72/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.1165e-08 - accuracy: 1.0000 - val_loss: 2.8931 - val_accuracy: 0.7411\n",
            "Epoch 73/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 9.9051e-09 - accuracy: 1.0000 - val_loss: 2.8896 - val_accuracy: 0.7411\n",
            "Epoch 74/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 8.9928e-09 - accuracy: 1.0000 - val_loss: 2.8897 - val_accuracy: 0.7426\n",
            "Epoch 75/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 7.9936e-09 - accuracy: 1.0000 - val_loss: 2.8840 - val_accuracy: 0.7426\n",
            "Epoch 76/330\n",
            "275/275 [==============================] - 10s 38ms/step - loss: 7.9502e-09 - accuracy: 1.0000 - val_loss: 2.8841 - val_accuracy: 0.7456\n",
            "Epoch 77/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 7.1682e-09 - accuracy: 1.0000 - val_loss: 2.8903 - val_accuracy: 0.7456\n",
            "Epoch 78/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.5600e-09 - accuracy: 1.0000 - val_loss: 2.8880 - val_accuracy: 0.7441\n",
            "Epoch 79/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.0821e-09 - accuracy: 1.0000 - val_loss: 2.8839 - val_accuracy: 0.7441\n",
            "Epoch 80/330\n",
            "275/275 [==============================] - 9s 35ms/step - loss: 6.1255e-09 - accuracy: 1.0000 - val_loss: 2.8850 - val_accuracy: 0.7441\n",
            "Epoch 81/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 5.5173e-09 - accuracy: 1.0000 - val_loss: 2.8826 - val_accuracy: 0.7456\n",
            "Epoch 82/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 5.3870e-09 - accuracy: 1.0000 - val_loss: 2.8848 - val_accuracy: 0.7426\n",
            "Epoch 83/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.9526e-09 - accuracy: 1.0000 - val_loss: 2.8901 - val_accuracy: 0.7441\n",
            "Epoch 84/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.3878e-09 - accuracy: 1.0000 - val_loss: 2.8966 - val_accuracy: 0.7426\n",
            "Epoch 85/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.4312e-09 - accuracy: 1.0000 - val_loss: 2.9024 - val_accuracy: 0.7426\n",
            "Epoch 86/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 4.1706e-09 - accuracy: 1.0000 - val_loss: 2.9180 - val_accuracy: 0.7456\n",
            "Epoch 87/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.8665e-09 - accuracy: 1.0000 - val_loss: 2.9417 - val_accuracy: 0.7515\n",
            "Epoch 88/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 3.3017e-09 - accuracy: 1.0000 - val_loss: 2.9683 - val_accuracy: 0.7500\n",
            "Epoch 89/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 3.1279e-09 - accuracy: 1.0000 - val_loss: 2.9467 - val_accuracy: 0.7485\n",
            "Epoch 90/330\n",
            "275/275 [==============================] - 9s 35ms/step - loss: 2.7369e-09 - accuracy: 1.0000 - val_loss: 2.9776 - val_accuracy: 0.7456\n",
            "Epoch 91/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.7804e-09 - accuracy: 1.0000 - val_loss: 3.0262 - val_accuracy: 0.7500\n",
            "Epoch 92/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.3025e-09 - accuracy: 1.0000 - val_loss: 3.0486 - val_accuracy: 0.7500\n",
            "Epoch 93/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.9984e-09 - accuracy: 1.0000 - val_loss: 3.0945 - val_accuracy: 0.7470\n",
            "Epoch 94/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.7377e-09 - accuracy: 1.0000 - val_loss: 3.1495 - val_accuracy: 0.7485\n",
            "Epoch 95/330\n",
            "275/275 [==============================] - 10s 34ms/step - loss: 1.9550e-09 - accuracy: 1.0000 - val_loss: 3.2246 - val_accuracy: 0.7574\n",
            "Epoch 96/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.4336e-09 - accuracy: 1.0000 - val_loss: 3.3544 - val_accuracy: 0.7411\n",
            "Epoch 97/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.8452 - accuracy: 0.7773 - val_loss: 2.3991 - val_accuracy: 0.6095\n",
            "Epoch 98/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 0.3236 - accuracy: 0.9056 - val_loss: 2.2381 - val_accuracy: 0.6331\n",
            "Epoch 99/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 0.0512 - accuracy: 0.9840 - val_loss: 2.9036 - val_accuracy: 0.6198\n",
            "Epoch 100/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 2.9914 - val_accuracy: 0.6243\n",
            "Epoch 101/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 3.0321 - val_accuracy: 0.6524\n",
            "Epoch 102/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 3.2173 - val_accuracy: 0.6524\n",
            "Epoch 103/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.9184e-04 - accuracy: 1.0000 - val_loss: 3.2840 - val_accuracy: 0.6553\n",
            "Epoch 104/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 5.8208e-05 - accuracy: 1.0000 - val_loss: 3.3190 - val_accuracy: 0.6524\n",
            "Epoch 105/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.2428e-05 - accuracy: 1.0000 - val_loss: 3.3540 - val_accuracy: 0.6568\n",
            "Epoch 106/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.4423e-05 - accuracy: 1.0000 - val_loss: 3.3884 - val_accuracy: 0.6568\n",
            "Epoch 107/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.0288e-05 - accuracy: 1.0000 - val_loss: 3.4137 - val_accuracy: 0.6568\n",
            "Epoch 108/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 7.6605e-06 - accuracy: 1.0000 - val_loss: 3.4337 - val_accuracy: 0.6583\n",
            "Epoch 109/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.7776e-06 - accuracy: 1.0000 - val_loss: 3.4591 - val_accuracy: 0.6598\n",
            "Epoch 110/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.3085e-06 - accuracy: 1.0000 - val_loss: 3.4813 - val_accuracy: 0.6612\n",
            "Epoch 111/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 3.2841e-06 - accuracy: 1.0000 - val_loss: 3.4935 - val_accuracy: 0.6612\n",
            "Epoch 112/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.6977e-06 - accuracy: 1.0000 - val_loss: 3.5072 - val_accuracy: 0.6612\n",
            "Epoch 113/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.2333e-06 - accuracy: 1.0000 - val_loss: 3.5279 - val_accuracy: 0.6612\n",
            "Epoch 114/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.8746e-06 - accuracy: 1.0000 - val_loss: 3.5387 - val_accuracy: 0.6642\n",
            "Epoch 115/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.5734e-06 - accuracy: 1.0000 - val_loss: 3.5538 - val_accuracy: 0.6642\n",
            "Epoch 116/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 1.3307e-06 - accuracy: 1.0000 - val_loss: 3.5710 - val_accuracy: 0.6657\n",
            "Epoch 117/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.1274e-06 - accuracy: 1.0000 - val_loss: 3.5861 - val_accuracy: 0.6657\n",
            "Epoch 118/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 9.6003e-07 - accuracy: 1.0000 - val_loss: 3.5997 - val_accuracy: 0.6672\n",
            "Epoch 119/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 8.2137e-07 - accuracy: 1.0000 - val_loss: 3.6150 - val_accuracy: 0.6686\n",
            "Epoch 120/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 7.0881e-07 - accuracy: 1.0000 - val_loss: 3.6268 - val_accuracy: 0.6686\n",
            "Epoch 121/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.1259e-07 - accuracy: 1.0000 - val_loss: 3.6418 - val_accuracy: 0.6672\n",
            "Epoch 122/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 5.3318e-07 - accuracy: 1.0000 - val_loss: 3.6567 - val_accuracy: 0.6672\n",
            "Epoch 123/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.6436e-07 - accuracy: 1.0000 - val_loss: 3.6666 - val_accuracy: 0.6686\n",
            "Epoch 124/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 4.0446e-07 - accuracy: 1.0000 - val_loss: 3.6759 - val_accuracy: 0.6701\n",
            "Epoch 125/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 3.5506e-07 - accuracy: 1.0000 - val_loss: 3.6911 - val_accuracy: 0.6686\n",
            "Epoch 126/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.1297e-07 - accuracy: 1.0000 - val_loss: 3.7034 - val_accuracy: 0.6686\n",
            "Epoch 127/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.7487e-07 - accuracy: 1.0000 - val_loss: 3.7132 - val_accuracy: 0.6701\n",
            "Epoch 128/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.4276e-07 - accuracy: 1.0000 - val_loss: 3.7242 - val_accuracy: 0.6716\n",
            "Epoch 129/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.1422e-07 - accuracy: 1.0000 - val_loss: 3.7381 - val_accuracy: 0.6716\n",
            "Epoch 130/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.8933e-07 - accuracy: 1.0000 - val_loss: 3.7479 - val_accuracy: 0.6716\n",
            "Epoch 131/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 1.6765e-07 - accuracy: 1.0000 - val_loss: 3.7574 - val_accuracy: 0.6701\n",
            "Epoch 132/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.4801e-07 - accuracy: 1.0000 - val_loss: 3.7717 - val_accuracy: 0.6701\n",
            "Epoch 133/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.3059e-07 - accuracy: 1.0000 - val_loss: 3.7800 - val_accuracy: 0.6701\n",
            "Epoch 134/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.1604e-07 - accuracy: 1.0000 - val_loss: 3.7938 - val_accuracy: 0.6701\n",
            "Epoch 135/330\n",
            "275/275 [==============================] - 10s 38ms/step - loss: 1.0231e-07 - accuracy: 1.0000 - val_loss: 3.8051 - val_accuracy: 0.6686\n",
            "Epoch 136/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 9.1145e-08 - accuracy: 1.0000 - val_loss: 3.8213 - val_accuracy: 0.6686\n",
            "Epoch 137/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 8.1413e-08 - accuracy: 1.0000 - val_loss: 3.8301 - val_accuracy: 0.6686\n",
            "Epoch 138/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 7.1074e-08 - accuracy: 1.0000 - val_loss: 3.8409 - val_accuracy: 0.6672\n",
            "Epoch 139/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.2776e-08 - accuracy: 1.0000 - val_loss: 3.8524 - val_accuracy: 0.6657\n",
            "Epoch 140/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 5.6042e-08 - accuracy: 1.0000 - val_loss: 3.8698 - val_accuracy: 0.6701\n",
            "Epoch 141/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 4.9178e-08 - accuracy: 1.0000 - val_loss: 3.8826 - val_accuracy: 0.6716\n",
            "Epoch 142/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.3748e-08 - accuracy: 1.0000 - val_loss: 3.8968 - val_accuracy: 0.6701\n",
            "Epoch 143/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.8882e-08 - accuracy: 1.0000 - val_loss: 3.9129 - val_accuracy: 0.6701\n",
            "Epoch 144/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.4016e-08 - accuracy: 1.0000 - val_loss: 3.9271 - val_accuracy: 0.6701\n",
            "Epoch 145/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.9802e-08 - accuracy: 1.0000 - val_loss: 3.9425 - val_accuracy: 0.6716\n",
            "Epoch 146/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 2.6457e-08 - accuracy: 1.0000 - val_loss: 3.9586 - val_accuracy: 0.6701\n",
            "Epoch 147/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.3112e-08 - accuracy: 1.0000 - val_loss: 3.9756 - val_accuracy: 0.6701\n",
            "Epoch 148/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.0505e-08 - accuracy: 1.0000 - val_loss: 3.9891 - val_accuracy: 0.6716\n",
            "Epoch 149/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.8246e-08 - accuracy: 1.0000 - val_loss: 4.0063 - val_accuracy: 0.6716\n",
            "Epoch 150/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.5813e-08 - accuracy: 1.0000 - val_loss: 4.0267 - val_accuracy: 0.6701\n",
            "Epoch 151/330\n",
            "275/275 [==============================] - 9s 35ms/step - loss: 1.3815e-08 - accuracy: 1.0000 - val_loss: 4.0463 - val_accuracy: 0.6686\n",
            "Epoch 152/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.2208e-08 - accuracy: 1.0000 - val_loss: 4.0705 - val_accuracy: 0.6657\n",
            "Epoch 153/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 1.0904e-08 - accuracy: 1.0000 - val_loss: 4.0981 - val_accuracy: 0.6657\n",
            "Epoch 154/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 9.5142e-09 - accuracy: 1.0000 - val_loss: 4.1195 - val_accuracy: 0.6642\n",
            "Epoch 155/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 8.3846e-09 - accuracy: 1.0000 - val_loss: 4.1514 - val_accuracy: 0.6657\n",
            "Epoch 156/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 7.9502e-09 - accuracy: 1.0000 - val_loss: 4.1758 - val_accuracy: 0.6672\n",
            "Epoch 157/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 7.1682e-09 - accuracy: 1.0000 - val_loss: 4.2052 - val_accuracy: 0.6701\n",
            "Epoch 158/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.2124e-09 - accuracy: 1.0000 - val_loss: 4.2459 - val_accuracy: 0.6716\n",
            "Epoch 159/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.4731e-09 - accuracy: 1.0000 - val_loss: 4.2710 - val_accuracy: 0.6701\n",
            "Epoch 160/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 5.2132e-09 - accuracy: 1.0000 - val_loss: 4.3392 - val_accuracy: 0.6701\n",
            "Epoch 161/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 5.3436e-09 - accuracy: 1.0000 - val_loss: 4.3864 - val_accuracy: 0.6672\n",
            "Epoch 162/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 5.8214e-09 - accuracy: 1.0000 - val_loss: 4.4138 - val_accuracy: 0.6657\n",
            "Epoch 163/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.5616e-09 - accuracy: 1.0000 - val_loss: 4.4833 - val_accuracy: 0.6672\n",
            "Epoch 164/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.7788e-09 - accuracy: 1.0000 - val_loss: 4.5407 - val_accuracy: 0.6686\n",
            "Epoch 165/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.6050e-09 - accuracy: 1.0000 - val_loss: 4.6090 - val_accuracy: 0.6657\n",
            "Epoch 166/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 5.0395e-09 - accuracy: 1.0000 - val_loss: 4.6819 - val_accuracy: 0.6657\n",
            "Epoch 167/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.3878e-09 - accuracy: 1.0000 - val_loss: 4.7924 - val_accuracy: 0.6612\n",
            "Epoch 168/330\n",
            "275/275 [==============================] - 9s 35ms/step - loss: 4.6485e-09 - accuracy: 1.0000 - val_loss: 4.8538 - val_accuracy: 0.6627\n",
            "Epoch 169/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 9.3404e-09 - accuracy: 1.0000 - val_loss: 4.8772 - val_accuracy: 0.6627\n",
            "Epoch 170/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.4328e-09 - accuracy: 1.0000 - val_loss: 5.0133 - val_accuracy: 0.6642\n",
            "Epoch 171/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 3.5189e-09 - accuracy: 1.0000 - val_loss: 5.2128 - val_accuracy: 0.6627\n",
            "Epoch 172/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 4.0403e-09 - accuracy: 1.0000 - val_loss: 5.3372 - val_accuracy: 0.6642\n",
            "Epoch 173/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 6.4297e-09 - accuracy: 1.0000 - val_loss: 5.3861 - val_accuracy: 0.6598\n",
            "Epoch 174/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 3.2583e-09 - accuracy: 1.0000 - val_loss: 5.4519 - val_accuracy: 0.6568\n",
            "Epoch 175/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0186 - accuracy: 0.9985 - val_loss: 7.7143 - val_accuracy: 0.5118\n",
            "Epoch 176/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.5433 - accuracy: 0.8870 - val_loss: 3.7774 - val_accuracy: 0.5932\n",
            "Epoch 177/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0529 - accuracy: 0.9880 - val_loss: 3.9964 - val_accuracy: 0.5976\n",
            "Epoch 178/330\n",
            "275/275 [==============================] - 9s 35ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 4.9802 - val_accuracy: 0.5947\n",
            "Epoch 179/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0229 - accuracy: 0.9938 - val_loss: 4.3216 - val_accuracy: 0.5991\n",
            "Epoch 180/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0403 - accuracy: 0.9905 - val_loss: 5.4451 - val_accuracy: 0.5873\n",
            "Epoch 181/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 5.8194 - val_accuracy: 0.5991\n",
            "Epoch 182/330\n",
            "275/275 [==============================] - 9s 34ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 6.7296 - val_accuracy: 0.5843\n",
            "Epoch 183/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0397 - accuracy: 0.9931 - val_loss: 5.6704 - val_accuracy: 0.5784\n",
            "Epoch 184/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 5.4014 - val_accuracy: 0.5858\n",
            "Epoch 185/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 5.4606 - val_accuracy: 0.5917\n",
            "Epoch 186/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.0981e-04 - accuracy: 1.0000 - val_loss: 5.5781 - val_accuracy: 0.5947\n",
            "Epoch 187/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.8576e-05 - accuracy: 1.0000 - val_loss: 5.6181 - val_accuracy: 0.5932\n",
            "Epoch 188/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 4.6776e-05 - accuracy: 1.0000 - val_loss: 5.6588 - val_accuracy: 0.5932\n",
            "Epoch 189/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.3492e-05 - accuracy: 1.0000 - val_loss: 5.6955 - val_accuracy: 0.5932\n",
            "Epoch 190/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.4826e-05 - accuracy: 1.0000 - val_loss: 5.7222 - val_accuracy: 0.5962\n",
            "Epoch 191/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.8676e-05 - accuracy: 1.0000 - val_loss: 5.7466 - val_accuracy: 0.5947\n",
            "Epoch 192/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.4339e-05 - accuracy: 1.0000 - val_loss: 5.7782 - val_accuracy: 0.5976\n",
            "Epoch 193/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.1258e-05 - accuracy: 1.0000 - val_loss: 5.8019 - val_accuracy: 0.5962\n",
            "Epoch 194/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 9.0472e-06 - accuracy: 1.0000 - val_loss: 5.8283 - val_accuracy: 0.5976\n",
            "Epoch 195/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 7.2308e-06 - accuracy: 1.0000 - val_loss: 5.8514 - val_accuracy: 0.5991\n",
            "Epoch 196/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 5.8561e-06 - accuracy: 1.0000 - val_loss: 5.8744 - val_accuracy: 0.5991\n",
            "Epoch 197/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.7465e-06 - accuracy: 1.0000 - val_loss: 5.8972 - val_accuracy: 0.6006\n",
            "Epoch 198/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.8706e-06 - accuracy: 1.0000 - val_loss: 5.9205 - val_accuracy: 0.6021\n",
            "Epoch 199/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.1814e-06 - accuracy: 1.0000 - val_loss: 5.9401 - val_accuracy: 0.6021\n",
            "Epoch 200/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.6533e-06 - accuracy: 1.0000 - val_loss: 5.9616 - val_accuracy: 0.6021\n",
            "Epoch 201/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.2149e-06 - accuracy: 1.0000 - val_loss: 5.9788 - val_accuracy: 0.5991\n",
            "Epoch 202/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.8641e-06 - accuracy: 1.0000 - val_loss: 5.9962 - val_accuracy: 0.6021\n",
            "Epoch 203/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.5748e-06 - accuracy: 1.0000 - val_loss: 6.0127 - val_accuracy: 0.6021\n",
            "Epoch 204/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.3388e-06 - accuracy: 1.0000 - val_loss: 6.0295 - val_accuracy: 0.6021\n",
            "Epoch 205/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.1353e-06 - accuracy: 1.0000 - val_loss: 6.0459 - val_accuracy: 0.6021\n",
            "Epoch 206/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 9.6583e-07 - accuracy: 1.0000 - val_loss: 6.0585 - val_accuracy: 0.6021\n",
            "Epoch 207/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 8.2132e-07 - accuracy: 1.0000 - val_loss: 6.0779 - val_accuracy: 0.6021\n",
            "Epoch 208/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 7.0120e-07 - accuracy: 1.0000 - val_loss: 6.0929 - val_accuracy: 0.6036\n",
            "Epoch 209/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.9783e-07 - accuracy: 1.0000 - val_loss: 6.1082 - val_accuracy: 0.6050\n",
            "Epoch 210/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.1175e-07 - accuracy: 1.0000 - val_loss: 6.1231 - val_accuracy: 0.6050\n",
            "Epoch 211/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.3830e-07 - accuracy: 1.0000 - val_loss: 6.1383 - val_accuracy: 0.6050\n",
            "Epoch 212/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.7624e-07 - accuracy: 1.0000 - val_loss: 6.1540 - val_accuracy: 0.6080\n",
            "Epoch 213/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.2415e-07 - accuracy: 1.0000 - val_loss: 6.1674 - val_accuracy: 0.6080\n",
            "Epoch 214/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.8124e-07 - accuracy: 1.0000 - val_loss: 6.1818 - val_accuracy: 0.6080\n",
            "Epoch 215/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.4284e-07 - accuracy: 1.0000 - val_loss: 6.1953 - val_accuracy: 0.6080\n",
            "Epoch 216/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.1043e-07 - accuracy: 1.0000 - val_loss: 6.2104 - val_accuracy: 0.6080\n",
            "Epoch 217/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.8285e-07 - accuracy: 1.0000 - val_loss: 6.2253 - val_accuracy: 0.6080\n",
            "Epoch 218/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.5817e-07 - accuracy: 1.0000 - val_loss: 6.2401 - val_accuracy: 0.6080\n",
            "Epoch 219/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.3815e-07 - accuracy: 1.0000 - val_loss: 6.2526 - val_accuracy: 0.6065\n",
            "Epoch 220/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.2051e-07 - accuracy: 1.0000 - val_loss: 6.2658 - val_accuracy: 0.6065\n",
            "Epoch 221/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.0526e-07 - accuracy: 1.0000 - val_loss: 6.2794 - val_accuracy: 0.6065\n",
            "Epoch 222/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 9.1578e-08 - accuracy: 1.0000 - val_loss: 6.2946 - val_accuracy: 0.6065\n",
            "Epoch 223/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 7.9414e-08 - accuracy: 1.0000 - val_loss: 6.3092 - val_accuracy: 0.6065\n",
            "Epoch 224/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.9509e-08 - accuracy: 1.0000 - val_loss: 6.3240 - val_accuracy: 0.6065\n",
            "Epoch 225/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 6.0082e-08 - accuracy: 1.0000 - val_loss: 6.3381 - val_accuracy: 0.6065\n",
            "Epoch 226/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.2393e-08 - accuracy: 1.0000 - val_loss: 6.3534 - val_accuracy: 0.6065\n",
            "Epoch 227/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.5616e-08 - accuracy: 1.0000 - val_loss: 6.3662 - val_accuracy: 0.6095\n",
            "Epoch 228/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.9577e-08 - accuracy: 1.0000 - val_loss: 6.3849 - val_accuracy: 0.6095\n",
            "Epoch 229/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.4320e-08 - accuracy: 1.0000 - val_loss: 6.3993 - val_accuracy: 0.6109\n",
            "Epoch 230/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.0019e-08 - accuracy: 1.0000 - val_loss: 6.4145 - val_accuracy: 0.6109\n",
            "Epoch 231/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.6283e-08 - accuracy: 1.0000 - val_loss: 6.4285 - val_accuracy: 0.6124\n",
            "Epoch 232/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.2721e-08 - accuracy: 1.0000 - val_loss: 6.4456 - val_accuracy: 0.6109\n",
            "Epoch 233/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.9636e-08 - accuracy: 1.0000 - val_loss: 6.4614 - val_accuracy: 0.6109\n",
            "Epoch 234/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.6900e-08 - accuracy: 1.0000 - val_loss: 6.4756 - val_accuracy: 0.6109\n",
            "Epoch 235/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.4554e-08 - accuracy: 1.0000 - val_loss: 6.4921 - val_accuracy: 0.6095\n",
            "Epoch 236/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.2512e-08 - accuracy: 1.0000 - val_loss: 6.5062 - val_accuracy: 0.6095\n",
            "Epoch 237/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.0904e-08 - accuracy: 1.0000 - val_loss: 6.5212 - val_accuracy: 0.6109\n",
            "Epoch 238/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 9.5576e-09 - accuracy: 1.0000 - val_loss: 6.5355 - val_accuracy: 0.6109\n",
            "Epoch 239/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 8.4281e-09 - accuracy: 1.0000 - val_loss: 6.5507 - val_accuracy: 0.6109\n",
            "Epoch 240/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 7.3420e-09 - accuracy: 1.0000 - val_loss: 6.5661 - val_accuracy: 0.6109\n",
            "Epoch 241/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 6.3428e-09 - accuracy: 1.0000 - val_loss: 6.5841 - val_accuracy: 0.6095\n",
            "Epoch 242/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.5608e-09 - accuracy: 1.0000 - val_loss: 6.5999 - val_accuracy: 0.6095\n",
            "Epoch 243/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 4.4747e-09 - accuracy: 1.0000 - val_loss: 6.6183 - val_accuracy: 0.6139\n",
            "Epoch 244/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 3.9099e-09 - accuracy: 1.0000 - val_loss: 6.6337 - val_accuracy: 0.6154\n",
            "Epoch 245/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 3.3886e-09 - accuracy: 1.0000 - val_loss: 6.6493 - val_accuracy: 0.6154\n",
            "Epoch 246/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.7804e-09 - accuracy: 1.0000 - val_loss: 6.6641 - val_accuracy: 0.6154\n",
            "Epoch 247/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 2.4328e-09 - accuracy: 1.0000 - val_loss: 6.6845 - val_accuracy: 0.6154\n",
            "Epoch 248/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.9115e-09 - accuracy: 1.0000 - val_loss: 6.6990 - val_accuracy: 0.6154\n",
            "Epoch 249/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.6074e-09 - accuracy: 1.0000 - val_loss: 6.7198 - val_accuracy: 0.6154\n",
            "Epoch 250/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.4336e-09 - accuracy: 1.0000 - val_loss: 6.7330 - val_accuracy: 0.6169\n",
            "Epoch 251/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.1295e-09 - accuracy: 1.0000 - val_loss: 6.7554 - val_accuracy: 0.6169\n",
            "Epoch 252/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 1.0861e-09 - accuracy: 1.0000 - val_loss: 6.7648 - val_accuracy: 0.6169\n",
            "Epoch 253/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 7.8199e-10 - accuracy: 1.0000 - val_loss: 6.7888 - val_accuracy: 0.6169\n",
            "Epoch 254/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 6.9510e-10 - accuracy: 1.0000 - val_loss: 6.8119 - val_accuracy: 0.6169\n",
            "Epoch 255/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.6477e-10 - accuracy: 1.0000 - val_loss: 6.8284 - val_accuracy: 0.6169\n",
            "Epoch 256/330\n",
            "275/275 [==============================] - 10s 35ms/step - loss: 5.2132e-10 - accuracy: 1.0000 - val_loss: 6.8423 - val_accuracy: 0.6169\n",
            "Epoch 257/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 4.3444e-10 - accuracy: 1.0000 - val_loss: 6.8678 - val_accuracy: 0.6169\n",
            "Epoch 258/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 3.0411e-10 - accuracy: 1.0000 - val_loss: 6.8915 - val_accuracy: 0.6169\n",
            "Epoch 259/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 3.4755e-10 - accuracy: 1.0000 - val_loss: 6.8899 - val_accuracy: 0.6169\n",
            "Epoch 260/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.7377e-10 - accuracy: 1.0000 - val_loss: 6.9170 - val_accuracy: 0.6169\n",
            "Epoch 261/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.7377e-10 - accuracy: 1.0000 - val_loss: 6.9450 - val_accuracy: 0.6198\n",
            "Epoch 262/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 1.7377e-10 - accuracy: 1.0000 - val_loss: 6.9731 - val_accuracy: 0.6198\n",
            "Epoch 263/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.1722e-10 - accuracy: 1.0000 - val_loss: 6.9982 - val_accuracy: 0.6169\n",
            "Epoch 264/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.3033e-10 - accuracy: 1.0000 - val_loss: 7.0306 - val_accuracy: 0.6198\n",
            "Epoch 265/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.3033e-10 - accuracy: 1.0000 - val_loss: 7.0616 - val_accuracy: 0.6198\n",
            "Epoch 266/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 8.6887e-11 - accuracy: 1.0000 - val_loss: 7.0621 - val_accuracy: 0.6198\n",
            "Epoch 267/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 4.3444e-11 - accuracy: 1.0000 - val_loss: 7.0967 - val_accuracy: 0.6228\n",
            "Epoch 268/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 4.3444e-11 - accuracy: 1.0000 - val_loss: 7.1349 - val_accuracy: 0.6228\n",
            "Epoch 269/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 4.3444e-11 - accuracy: 1.0000 - val_loss: 7.1686 - val_accuracy: 0.6228\n",
            "Epoch 270/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1986 - val_accuracy: 0.6228\n",
            "Epoch 271/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2341 - val_accuracy: 0.6228\n",
            "Epoch 272/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2647 - val_accuracy: 0.6228\n",
            "Epoch 273/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2967 - val_accuracy: 0.6257\n",
            "Epoch 274/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3327 - val_accuracy: 0.6257\n",
            "Epoch 275/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 8.0668e-08 - accuracy: 1.0000 - val_loss: 8.3903 - val_accuracy: 0.6095\n",
            "Epoch 276/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 0.5141 - accuracy: 0.9308 - val_loss: 7.1461 - val_accuracy: 0.5503\n",
            "Epoch 277/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 0.0696 - accuracy: 0.9869 - val_loss: 6.8391 - val_accuracy: 0.5754\n",
            "Epoch 278/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 9.0703 - val_accuracy: 0.5962\n",
            "Epoch 279/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 7.5500 - val_accuracy: 0.6006\n",
            "Epoch 280/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 9.5732e-04 - accuracy: 0.9996 - val_loss: 7.9224 - val_accuracy: 0.6006\n",
            "Epoch 281/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.1473e-04 - accuracy: 1.0000 - val_loss: 8.2319 - val_accuracy: 0.6006\n",
            "Epoch 282/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 2.1772e-04 - accuracy: 1.0000 - val_loss: 8.2968 - val_accuracy: 0.5962\n",
            "Epoch 283/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 9.2842e-05 - accuracy: 1.0000 - val_loss: 8.3544 - val_accuracy: 0.5976\n",
            "Epoch 284/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.9829e-05 - accuracy: 1.0000 - val_loss: 8.4096 - val_accuracy: 0.5962\n",
            "Epoch 285/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 3.9989e-05 - accuracy: 1.0000 - val_loss: 8.4582 - val_accuracy: 0.5947\n",
            "Epoch 286/330\n",
            "275/275 [==============================] - 10s 38ms/step - loss: 3.0361e-05 - accuracy: 1.0000 - val_loss: 8.4942 - val_accuracy: 0.5917\n",
            "Epoch 287/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.4563e-05 - accuracy: 1.0000 - val_loss: 8.5267 - val_accuracy: 0.5902\n",
            "Epoch 288/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.9514e-05 - accuracy: 1.0000 - val_loss: 8.5547 - val_accuracy: 0.5888\n",
            "Epoch 289/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 1.5998e-05 - accuracy: 1.0000 - val_loss: 8.5812 - val_accuracy: 0.5888\n",
            "Epoch 290/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 1.3236e-05 - accuracy: 1.0000 - val_loss: 8.6043 - val_accuracy: 0.5888\n",
            "Epoch 291/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 1.0866e-05 - accuracy: 1.0000 - val_loss: 8.6260 - val_accuracy: 0.5873\n",
            "Epoch 292/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 8.9196e-06 - accuracy: 1.0000 - val_loss: 8.6469 - val_accuracy: 0.5873\n",
            "Epoch 293/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 7.4032e-06 - accuracy: 1.0000 - val_loss: 8.6685 - val_accuracy: 0.5873\n",
            "Epoch 294/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 6.1034e-06 - accuracy: 1.0000 - val_loss: 8.6868 - val_accuracy: 0.5888\n",
            "Epoch 295/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.0785e-06 - accuracy: 1.0000 - val_loss: 8.7068 - val_accuracy: 0.5902\n",
            "Epoch 296/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 4.2545e-06 - accuracy: 1.0000 - val_loss: 8.7236 - val_accuracy: 0.5902\n",
            "Epoch 297/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 3.5547e-06 - accuracy: 1.0000 - val_loss: 8.7442 - val_accuracy: 0.5888\n",
            "Epoch 298/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 2.9708e-06 - accuracy: 1.0000 - val_loss: 8.7609 - val_accuracy: 0.5902\n",
            "Epoch 299/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 2.5003e-06 - accuracy: 1.0000 - val_loss: 8.7791 - val_accuracy: 0.5888\n",
            "Epoch 300/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.0860e-06 - accuracy: 1.0000 - val_loss: 8.7969 - val_accuracy: 0.5888\n",
            "Epoch 301/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.7476e-06 - accuracy: 1.0000 - val_loss: 8.8147 - val_accuracy: 0.5888\n",
            "Epoch 302/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.4472e-06 - accuracy: 1.0000 - val_loss: 8.8337 - val_accuracy: 0.5888\n",
            "Epoch 303/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.2204e-06 - accuracy: 1.0000 - val_loss: 8.8508 - val_accuracy: 0.5858\n",
            "Epoch 304/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.0159e-06 - accuracy: 1.0000 - val_loss: 8.8690 - val_accuracy: 0.5858\n",
            "Epoch 305/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 8.3530e-07 - accuracy: 1.0000 - val_loss: 8.8857 - val_accuracy: 0.5858\n",
            "Epoch 306/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 6.9657e-07 - accuracy: 1.0000 - val_loss: 8.9029 - val_accuracy: 0.5858\n",
            "Epoch 307/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.7835e-07 - accuracy: 1.0000 - val_loss: 8.9185 - val_accuracy: 0.5858\n",
            "Epoch 308/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 4.8498e-07 - accuracy: 1.0000 - val_loss: 8.9350 - val_accuracy: 0.5858\n",
            "Epoch 309/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 4.0503e-07 - accuracy: 1.0000 - val_loss: 8.9524 - val_accuracy: 0.5858\n",
            "Epoch 310/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 3.3960e-07 - accuracy: 1.0000 - val_loss: 8.9687 - val_accuracy: 0.5858\n",
            "Epoch 311/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.8458e-07 - accuracy: 1.0000 - val_loss: 8.9840 - val_accuracy: 0.5858\n",
            "Epoch 312/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.3981e-07 - accuracy: 1.0000 - val_loss: 8.9996 - val_accuracy: 0.5843\n",
            "Epoch 313/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.0211e-07 - accuracy: 1.0000 - val_loss: 9.0145 - val_accuracy: 0.5843\n",
            "Epoch 314/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.6984e-07 - accuracy: 1.0000 - val_loss: 9.0309 - val_accuracy: 0.5843\n",
            "Epoch 315/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.4257e-07 - accuracy: 1.0000 - val_loss: 9.0450 - val_accuracy: 0.5843\n",
            "Epoch 316/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 1.2085e-07 - accuracy: 1.0000 - val_loss: 9.0607 - val_accuracy: 0.5843\n",
            "Epoch 317/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 1.0322e-07 - accuracy: 1.0000 - val_loss: 9.0759 - val_accuracy: 0.5858\n",
            "Epoch 318/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 8.8359e-08 - accuracy: 1.0000 - val_loss: 9.0907 - val_accuracy: 0.5873\n",
            "Epoch 319/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 7.5154e-08 - accuracy: 1.0000 - val_loss: 9.1061 - val_accuracy: 0.5873\n",
            "Epoch 320/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 6.4598e-08 - accuracy: 1.0000 - val_loss: 9.1214 - val_accuracy: 0.5873\n",
            "Epoch 321/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 5.5172e-08 - accuracy: 1.0000 - val_loss: 9.1354 - val_accuracy: 0.5828\n",
            "Epoch 322/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 4.7570e-08 - accuracy: 1.0000 - val_loss: 9.1522 - val_accuracy: 0.5828\n",
            "Epoch 323/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 4.1140e-08 - accuracy: 1.0000 - val_loss: 9.1671 - val_accuracy: 0.5814\n",
            "Epoch 324/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 3.5580e-08 - accuracy: 1.0000 - val_loss: 9.1813 - val_accuracy: 0.5799\n",
            "Epoch 325/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 3.0845e-08 - accuracy: 1.0000 - val_loss: 9.1975 - val_accuracy: 0.5799\n",
            "Epoch 326/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 2.6544e-08 - accuracy: 1.0000 - val_loss: 9.2135 - val_accuracy: 0.5799\n",
            "Epoch 327/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.3416e-08 - accuracy: 1.0000 - val_loss: 9.2278 - val_accuracy: 0.5799\n",
            "Epoch 328/330\n",
            "275/275 [==============================] - 10s 36ms/step - loss: 2.0245e-08 - accuracy: 1.0000 - val_loss: 9.2452 - val_accuracy: 0.5814\n",
            "Epoch 329/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 1.7508e-08 - accuracy: 1.0000 - val_loss: 9.2627 - val_accuracy: 0.5814\n",
            "Epoch 330/330\n",
            "275/275 [==============================] - 10s 37ms/step - loss: 1.5379e-08 - accuracy: 1.0000 - val_loss: 9.2787 - val_accuracy: 0.5828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Sangcute.h5')"
      ],
      "metadata": {
        "id": "YGqQGfG2yZmi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train','validation'],loc='upper_left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "iH2XRYWH28Xo",
        "outputId": "9afe7001-835c-4cb1-f9d2-1a046ebb4e6b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: MatplotlibDeprecationWarning: Unrecognized location 'upper_left'. Falling back on 'best'; valid locations are\n",
            "\tbest\n",
            "\tupper right\n",
            "\tupper left\n",
            "\tlower left\n",
            "\tlower right\n",
            "\tright\n",
            "\tcenter left\n",
            "\tcenter right\n",
            "\tlower center\n",
            "\tupper center\n",
            "\tcenter\n",
            "This will raise an exception in 3.3.\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdf06715590>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rhp8A33r3AHF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}